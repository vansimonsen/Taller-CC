{
 "metadata": {
  "name": "",
  "signature": "sha256:71b2c73159950ff29e765fece04822200ac1ccf1b73d05172e430dab0fb8d672"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "# GMRes without optimization\n",
      "def gmres(A,b,x0,it):\n",
      "    # Definition of Q and H matrices\n",
      "    Q = np.zeros((b.shape[0], it+1))\n",
      "    H = np.zeros((it+1,it))\n",
      "    \n",
      "    r = b - np.dot(A,x0)\n",
      "    beta0 = np.linalg.norm(b)\n",
      "    beta1 = np.linalg.norm(r)\n",
      "    Q[:,0] = r/beta1\n",
      "    \n",
      "    for i in range(it):\n",
      "        e = np.zeros((i+2))\n",
      "        e[0] = 1\n",
      "        \n",
      "        w = np.dot(A,Q[:,i])\n",
      "        \n",
      "        for j in range(i):\n",
      "            h = np.dot(Q[:,j],w)\n",
      "            w -= h*Q[:,j]\n",
      "            H[j,i] = h\n",
      "        \n",
      "        H[i+1,i] = np.linalg.norm(w)\n",
      "        \n",
      "        if H[i+1,i] != 0:\n",
      "            Q[:,i+1] = w/H[i+1,i]\n",
      "        \n",
      "        y,_,_,_ = np.linalg.lstsq(H[:i+2,:i+1], beta1*e)\n",
      "        \n",
      "        if H[i+1,i] == 0:\n",
      "            break\n",
      "    \n",
      "    return x0 + np.dot(Q[:,:-1], y)\n",
      "    \n",
      "# Optimized version of GMRes, pendent\n",
      "def opt_gmres(A,b,x0,it):\n",
      "    # Definition of Q and H matrices\n",
      "    Q = np.zeros((b.shape[0], it+1))\n",
      "    H = np.zeros((it+1,it))\n",
      "    \n",
      "    r = b - np.dot(A,x0)\n",
      "    beta0 = np.linalg.norm(b)\n",
      "    beta1 = np.linalg.norm(r)\n",
      "    Q[:,0] = r/beta1\n",
      "    \n",
      "    for i in range(it):\n",
      "        e = np.zeros((i+2))\n",
      "        e[0] = 1\n",
      "        \n",
      "        w = np.dot(A,Q[:,i])\n",
      "        \n",
      "        for j in range(i):\n",
      "            h = np.dot(Q[:,j],w)\n",
      "            w -= h*Q[:,j]\n",
      "            H[j,i] = h\n",
      "        \n",
      "        H[i+1,i] = np.linalg.norm(w)\n",
      "        \n",
      "        if H[i+1,i] != 0:\n",
      "            Q[:,i+1] = w/H[i+1,i]\n",
      "        \n",
      "        y,_,_,_ = np.linalg.lstsq(H[:i+2,:i+1], beta1*e)\n",
      "        \n",
      "        if H[i+1,i] == 0:\n",
      "            break\n",
      "    \n",
      "    return x0 + np.dot(Q[:,:-1], y)\n",
      "    \n",
      "# GMres with preconditioner proposed by the paper.\n",
      "# TODO: BORRAR EL M^-1, EL PROFE NOS MATAR\u00c1!\n",
      "def prec_gmres(A,b,x0,it,M):\n",
      "    # Definition of Q and H matrices\n",
      "    Q = np.zeros((b.shape[0], it+1))\n",
      "    H = np.zeros((it+1,it))\n",
      "    Z = np.zeros((b.shape[0], it+1))\n",
      "    \n",
      "    r = b - np.dot(A,x0)\n",
      "    beta0 = np.linalg.norm(b)\n",
      "    beta1 = np.linalg.norm(r)\n",
      "    Q[:,0] = r/beta1\n",
      "    M_1 = np.linalg.inv(M)\n",
      "    \n",
      "    for i in range(it):\n",
      "        e = np.zeros((i+2))\n",
      "        e[0] = 1\n",
      "        \n",
      "        Z[:,i] = np.dot(M_1,Q[:,i])\n",
      "        w = np.dot(A,Z[:,i])\n",
      "        \n",
      "        for j in range(i):\n",
      "            h = np.dot(Q[:,j],w)\n",
      "            w -= h*Q[:,j]\n",
      "            H[j,i] = h\n",
      "        \n",
      "        H[i+1,i] = np.linalg.norm(w)\n",
      "        \n",
      "        if H[i+1,i] != 0:\n",
      "            Q[:,i+1] = w/H[i+1,i]\n",
      "        \n",
      "        y,_,_,_ = np.linalg.lstsq(H[:i+2,:i+1], beta1*e)\n",
      "        \n",
      "        if H[i+1,i] == 0:\n",
      "            break\n",
      "    return x0 + np.dot(Z[:,:-1], y)\n",
      "    \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}